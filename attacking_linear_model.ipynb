{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkmYqlc1wfqO"
      },
      "source": [
        "# Атака на линейную модель\n",
        "\n",
        "В этой блокнотебудет показана простейшая атака на линейную модель бинарной классификации\n",
        "\n",
        "\n",
        "В примере будет использоваться датасет `MNIST` содержащий рукописные цифры. Постараемся отличить 3 от 7..\n",
        "\n",
        "Возьмем обучающую выборку $(x_1, y_1), \\cdots, (x_n, y_n)$ с $x_i \\in \\mathbb{R}^{p}$ and $y_i = \\pm 1$, линейная модель строит функцию принятия решения на основе гиперплоскости:\n",
        "\n",
        "$$ y = \\text{sign}(w^{\\top}x + b) \\enspace, $$\n",
        "\n",
        "где $w \\in \\mathbb{R}^p$ и $b\\in \\mathbb{R}$. \n",
        "\n",
        "В примере будет использована логичтическая регрессия\n",
        "\n",
        "\n",
        "<img src=\"\n",
        "https://pierreablingithub.files.wordpress.com/2019/04/fig.png\" align=\"center\" hspace=\"10px\" vspace=\"0px\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OXzNLwT5wfqS"
      },
      "source": [
        "## Подготовка данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "YgKGF1GKwfqU"
      },
      "outputs": [],
      "source": [
        "# импорт библиотек\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "plVmyC6iwfqa"
      },
      "source": [
        "### Берем датасет `MNIST`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "EXkhMx68wfqc"
      },
      "outputs": [],
      "source": [
        "X, y = fetch_openml('mnist_784', version=1, return_X_y=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hEdYcI8bwfqg"
      },
      "source": [
        "## Нас итересуют только выборки, содержащие 3 или 7:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "S6X9Ol6Rwfqh"
      },
      "outputs": [],
      "source": [
        "idxs = (y == '3') | (y == '7')\n",
        "y = y[idxs]\n",
        "X = X[idxs]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYd--ZE8wfql"
      },
      "source": [
        "### Разделим набор данных на обучающий или тестовый"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "h3DEYo79wfqm"
      },
      "outputs": [],
      "source": [
        "random_state = np.random.RandomState(0)\n",
        "\n",
        "\n",
        "\n",
        "X_train, X_test, y_train, y_test = \\\n",
        "  train_test_split(X, y, train_size=12000, test_size=2000,\n",
        "                   random_state=random_state)\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3-_BNV1wfqt"
      },
      "source": [
        "## Подгонка модели\n",
        "\n",
        "Применим логистическую регрессию к обучающим данным"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qVy0l_Ylwfqu",
        "outputId": "58f54e58-2c5e-45be-a0ee-035ba96a6ee1"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(max_iter=1000)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "logreg = LogisticRegression(solver='lbfgs', max_iter=1000)\n",
        "logreg.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krYUW06Swfqz"
      },
      "source": [
        "Вычислим  оценку предсказания по тестовым данным"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QBllCyPTwfq0",
        "outputId": "5e2b2f9f-5aaa-4b85-8734-346ae49bfdbb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "test score = 0.9855\n"
          ]
        }
      ],
      "source": [
        "print('test score = {}'.format(logreg.score(X_test, y_test)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_xUg3mPLwfq5"
      },
      "source": [
        "Это очень высокий показатель, очевидно, что гиперплоскость хорошо разделяет два класса."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UtU3VHqlwfq6"
      },
      "source": [
        "## Атака\n",
        "\n",
        "Возьмем обучающую выборку для x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "o3vyBABewfq8"
      },
      "outputs": [],
      "source": [
        "x = X_train[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "mUdsI2Wu_z6R"
      },
      "outputs": [],
      "source": [
        "def show(x):\n",
        "    plt.title('Предсказание: %s. Уверенность: %d %%' %\n",
        "              (logreg.predict([x])[0],\n",
        "               100 * logreg.predict_proba([x]).max()),\n",
        "              fontsize=18)\n",
        "    plt.imshow(scaler.inverse_transform(x).reshape(28, 28),\n",
        "               cmap=plt.cm.gray_r, vmin=0, vmax=255)\n",
        "    plt.axis('off')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "g06YWfQwwfrB",
        "outputId": "b2cd325e-3f25-40cc-d5d4-331c0df05fe1"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-a2ecb4f1fe6f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-8-fd095d180cdc>\u001b[0m in \u001b[0;36mshow\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      4\u001b[0m                100 * logreg.predict_proba([x]).max()),\n\u001b[1;32m      5\u001b[0m               fontsize=18)\n\u001b[0;32m----> 6\u001b[0;31m     plt.imshow(scaler.inverse_transform(x).reshape(28, 28),\n\u001b[0m\u001b[1;32m      7\u001b[0m                cmap=plt.cm.gray_r, vmin=0, vmax=255)\n\u001b[1;32m      8\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'off'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36minverse_transform\u001b[0;34m(self, X, copy)\u001b[0m\n\u001b[1;32m   1020\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1021\u001b[0m             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1022\u001b[0;31m             \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"allow-nan\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1023\u001b[0m         )\n\u001b[1;32m   1024\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    771\u001b[0m                     \u001b[0;34m\"Reshape your data either using array.reshape(-1, 1) if \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    772\u001b[0m                     \u001b[0;34m\"your data has a single feature or array.reshape(1, -1) \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 773\u001b[0;31m                     \u001b[0;34m\"if it contains a single sample.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    774\u001b[0m                 )\n\u001b[1;32m    775\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[ 0.          0.          0.          0.          0.          0.\n  0.          0.          0.          0.          0.          0.\n  0.          0.          0.          0.          0.          0.\n  0.          0.          0.          0.          0.          0.\n  0.          0.          0.          0.          0.          0.\n  0.          0.          0.          0.          0.          0.\n  0.          0.          0.          0.          0.          0.\n  0.          0.          0.          0.          0.          0.\n  0.          0.          0.          0.          0.          0.\n  0.          0.          0.          0.          0.          0.\n  0.          0.          0.          0.          0.         -0.00912909\n -0.0128142  -0.01399234 -0.01329877 -0.01569324 -0.01101569 -0.01229484\n -0.00912909 -0.00912909 -0.00912909  0.          0.          0.\n  0.          0.          0.          0.          0.          0.\n  0.          0.          0.          0.         -0.00912909 -0.0205041\n -0.02364617 -0.03295654 -0.04979012 -0.06535883 -0.08195704 -0.10301645\n -0.11729647 -0.12455411 -0.1266447  -0.12240996 -0.11347622 -0.10408552\n -0.08789102 -0.06704347 -0.05060069 -0.03651343 -0.01746172 -0.01291031\n -0.00912909  0.          0.          0.          0.         -0.00912909\n -0.00912909 -0.02176366 -0.03485694 -0.06467913 -0.09953772  0.28503924\n  4.10764567  5.27161301  4.16362779  3.49407993  3.15469958  2.94967579\n  2.79720651  1.33892553 -0.04926682 -0.32342355 -0.26604307 -0.20585876\n -0.14901316 -0.10005418 -0.06293655 -0.02370254 -0.00912909  0.\n  0.          0.          0.         -0.00912909 -0.01236098 -0.03619199\n -0.09014967 -0.14314234 -0.20921611  2.0579162   3.46590069  2.72268841\n  2.25631922  1.5381871   1.1388043   1.55188474  1.60800204  1.65976426\n  1.38912222 -0.35224111 -0.47395154 -0.37416849 -0.27945779 -0.19260332\n -0.11399069 -0.05063087 -0.01988897  0.          0.          0.\n  0.         -0.00912909 -0.02710629 -0.07272518 -0.14566288 -0.22783124\n -0.3158687   0.09225857  1.75595387  1.05597097 -0.25670087 -0.75485805\n -0.90442084 -0.73723579  0.34138143  1.28004155  1.34049889  0.38777068\n -0.68704142 -0.54959723 -0.41813418 -0.29660239 -0.18555383 -0.09499045\n -0.03217528 -0.00912909  0.          0.         -0.00912909 -0.0260475\n -0.05659014 -0.12360818 -0.22109236 -0.32448727 -0.44282081 -0.57222813\n -0.71166842 -0.85563743 -0.97605269 -1.06483405 -1.11591462 -1.15818993\n -1.11495512  0.72523974  1.07785257  0.36764086 -1.0563562  -0.84267477\n -0.62841111 -0.4414864  -0.28276649 -0.16051184 -0.06812809 -0.02389667\n  0.          0.         -0.00912909 -0.03769866 -0.09319692 -0.17825365\n -0.27984925 -0.39484741 -0.52195377 -0.66250721 -0.80845402 -0.95268131\n -1.06380824 -1.12749187 -1.15925084 -1.19447801 -0.62557142  0.96985191\n  0.88847389  0.08465447 -1.38616691 -1.0706356  -0.76415817 -0.52483634\n -0.33502701 -0.18978846 -0.09102996 -0.03015375  0.          0.\n -0.01389352 -0.04692096 -0.11485313 -0.19796674 -0.29937914 -0.41078549\n -0.53113826 -0.65835621 -0.78420373 -0.89524126 -0.96494584 -0.99828864\n -1.01200251 -0.85782967  0.68667739  1.0176447   0.88027117 -0.37258328\n -1.51582661 -1.13704997 -0.79426296 -0.53168821 -0.33940441 -0.18939745\n -0.0837407  -0.03204018 -0.00912909 -0.00912909 -0.01293549 -0.04847118\n -0.11275547 -0.19159807 -0.27879055 -0.37365028 -0.47739571 -0.5780388\n -0.67527901 -0.74766887 -0.24072213  0.5125615   0.82133055  1.14566715\n  1.36085042  1.16940446  0.36079469 -1.60283178 -1.43257395 -1.06936132\n -0.73617007 -0.48549224 -0.30326006 -0.16266969 -0.06785778 -0.02687902\n -0.00912909 -0.00912909 -0.01531182 -0.04584378 -0.09907363 -0.1630304\n -0.2359539  -0.31287324 -0.39735002 -0.48492561 -0.56493769  0.05173882\n  1.88027891  1.86406434  1.74294061  1.56656701  1.37438936  1.20572864\n -0.39814376 -1.47178202 -1.30423937 -0.95195358 -0.65019306 -0.41656341\n -0.24733727 -0.12702341 -0.04968954 -0.01582157  0.          0.\n -0.01186156 -0.03559662 -0.07302214 -0.12272453 -0.18487008 -0.25426986\n -0.32860363 -0.41309499 -0.49850588  0.50158867  1.97134879  1.7625413\n  1.55886052  1.38027493  1.26104439  1.15331161  0.94278247 -0.33578029\n -1.03325162 -0.87249045 -0.5739057  -0.34878633 -0.20227514 -0.09391112\n -0.03669573 -0.01775861 -0.00912909  0.          0.         -0.0237145\n -0.05148226 -0.09004392 -0.14520256 -0.20914248 -0.27982042 -0.36668505\n -0.46100905 -0.43125353 -0.35490772 -0.4652962  -0.54783714  0.3342512\n  0.78179944  1.14226652  0.95083098  0.87909692  0.04712045 -0.86139615\n -0.53957536 -0.32466522 -0.17977778 -0.09257959 -0.04518768 -0.02567553\n -0.0103167   0.          0.         -0.01536928 -0.03702788 -0.06969568\n -0.12208311 -0.17904962 -0.24331472 -0.3237014  -0.41699468 -0.51557563\n -0.60956119 -0.68829083 -0.73948136 -0.7787858  -0.82140707 -0.68454526\n  0.47115031  0.83808065  0.70008785 -0.27962531 -0.55705866 -0.34471937\n -0.20507183 -0.11577011 -0.05709439 -0.02188031 -0.00912909  0.\n  0.         -0.00912909 -0.03268513 -0.06390002 -0.11088462 -0.16209741\n -0.21430761 -0.27304256 -0.34457211 -0.4263094  -0.50092638 -0.55510296\n -0.58696627 -0.63505724 -0.79028868 -1.09046389 -0.91202248  0.83858094\n  1.08159772  0.98097748 -0.5967452  -0.38679397 -0.24855051 -0.14238365\n -0.06862345 -0.02415271 -0.01545536  0.          0.         -0.01287449\n -0.04158323 -0.08297311 -0.12436929 -0.1619625  -0.20055862 -0.23566297\n -0.2839728  -0.33470892 -0.37849694 -0.41171042 -0.44564107 -0.53697306\n -0.74087636 -1.00559748 -1.25928421 -0.06331404  1.19422152  1.37780559\n -0.33042804 -0.41628799 -0.27353794 -0.16191738 -0.07237974 -0.02142618\n -0.01255693  0.          0.         -0.01684823 -0.05028841 -0.10860059\n -0.15536353 -0.18826823 -0.20949764 -0.23483578 -0.2590744  -0.27207036\n -0.29009909 -0.32072559 -0.38634329 -0.5356444  -0.74806577 -0.97081161\n -1.1249919  -0.38310028  1.33436118  1.61090439  0.42478569 -0.4184966\n -0.28321567 -0.16490899 -0.07197593 -0.02296883 -0.01138591  0.\n -0.00912909 -0.01318125 -0.06600993 -0.13997902 -0.19734118 -0.24200657\n -0.26885101 -0.28471335 -0.28645846 -0.27876661 -0.28267885 -0.32363483\n -0.43277243 -0.60549862 -0.80672144 -0.97888872 -1.04945544 -0.2615798\n  1.44835159  1.70611828  0.79842283 -0.40535521 -0.27832265 -0.15717088\n -0.06188327 -0.01957644 -0.01210832  0.          0.         -0.02215212\n -0.07828978 -0.16413194 -0.23959751 -0.30206532 -0.34191926 -0.3643209\n  0.88083694  2.91356802  1.90484177 -0.12397826 -0.54956743 -0.72315073\n -0.9100444  -1.02444263 -1.0346015  -0.2206272   1.51343124  1.8188094\n -0.03625349 -0.37709753 -0.25228303 -0.13465246 -0.0469328  -0.01540047\n  0.          0.          0.         -0.02092963 -0.08563374 -0.17992324\n -0.2653014  -0.34588653 -0.41030074 -0.45836206  1.91564553  2.53424735\n  2.43420891  0.39822075 -0.74894584 -0.93204564 -1.09220326 -1.14106755\n -1.06494288  0.5998356   1.59009437  1.9075923  -0.09237927 -0.32607299\n -0.21215623 -0.10553673 -0.0358407  -0.01374707 -0.00912909  0.\n  0.         -0.02074574 -0.08273394 -0.17052293 -0.26092004 -0.35224776\n -0.45072853 -0.53830655  1.23101097  1.79176369  1.62091824  1.14163199\n  0.31662705 -0.60047807 -1.07613376 -0.36942647  0.25639617  1.41520735\n  1.78666569  1.64467685 -0.37600695 -0.25679048 -0.15074975 -0.06876484\n -0.02395339 -0.01259872 -0.00912909  0.          0.         -0.01151568\n -0.06811476 -0.1402031  -0.22549705 -0.31931886 -0.43001391 -0.5522712\n -0.62903528  0.34939193  1.1138731   1.0590524   0.96021573  0.91647568\n  0.95154709  1.08981007  1.33798723  1.71307411  1.94873868  0.56851646\n -0.27505128 -0.17602901 -0.09682146 -0.0406698  -0.01901176 -0.01290926\n -0.00912909  0.          0.         -0.00912909 -0.0483067  -0.10111437\n -0.17327266 -0.25147156 -0.35236047 -0.48148159 -0.62821806 -0.7944916\n -0.98646155 -0.27524774  0.20858051  0.95143608  1.18102223  1.42653358\n  1.50298527  1.05280221  0.04785723 -0.27028057 -0.17653405 -0.10462078\n -0.05558918 -0.02405694 -0.0189474  -0.01171031 -0.00912909  0.\n  0.          0.         -0.01970472 -0.05961415 -0.11340113 -0.16896795\n -0.24560663 -0.3417277  -0.45471578 -0.57192629 -0.69683136 -0.7905711\n -0.82954818 -0.80605795 -0.71850003 -0.59968365 -0.47214005 -0.35625161\n -0.25251309 -0.17015975 -0.10931851 -0.06388914 -0.03809062 -0.01630948\n -0.01600848 -0.00912909  0.          0.          0.          0.\n -0.01178126 -0.02396793 -0.05705642 -0.09915094 -0.16043388 -0.23304943\n -0.31477489 -0.3937742  -0.46387849 -0.51169661 -0.52594432 -0.5097326\n -0.46585537 -0.4005713  -0.32692011 -0.2525531  -0.18210375 -0.12962598\n -0.08595303 -0.05370004 -0.03624623 -0.01494159 -0.01510938  0.\n  0.          0.          0.          0.          0.          0.\n -0.02638242 -0.05933418 -0.10585945 -0.16021865 -0.21875991 -0.26815908\n -0.31136171 -0.34426041 -0.3547607  -0.35072955 -0.32726841 -0.28748253\n -0.2406837  -0.1916395  -0.14228268 -0.10043416 -0.06366757 -0.04214432\n -0.02934465 -0.01423477  0.          0.          0.          0.\n  0.          0.          0.          0.         -0.01237812 -0.01591208\n -0.02782645 -0.04192724 -0.05478838 -0.06496949 -0.09037992 -0.10082317\n -0.11207574 -0.12103277 -0.12784512 -0.12196171 -0.10901066 -0.09075535\n -0.06926159 -0.04637211 -0.03159184 -0.01966468 -0.01452304 -0.00912909\n  0.          0.          0.          0.        ].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "show(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHQH0ot1wfrF"
      },
      "source": [
        "Алгоритм уверен, что это 7"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5D_B4jewfrJ"
      },
      "source": [
        "Возмьем некоторый `x`, переместим его в гиперплоскости выполнив:\n",
        "\n",
        "$$ x_1 =  x - \\frac{w^{\\top}x + b}{w^{\\top}w}w$$ \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iTMT4pL8wfrJ"
      },
      "outputs": [],
      "source": [
        "w = logreg.coef_[0]\n",
        "b = logreg.intercept_\n",
        "\n",
        "x1 = x - (np.dot(w, x) + b) / np.dot(w, w) * w"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKAFm4luwfrM"
      },
      "source": [
        "При этом алгоритм с равной вероятностью предсказывает два класса:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y6mKi9InwfrM"
      },
      "outputs": [],
      "source": [
        "logreg.predict_proba([x1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0uWalmJwfrR"
      },
      "source": [
        "Как выглядит новый x?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1MZQbECmwfrR"
      },
      "outputs": [],
      "source": [
        "show(x1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nxi7TSSuwfrW"
      },
      "source": [
        "Все еще выглядит как 7 !\n",
        "\n",
        "Переместим x на другую сторону гиперплоскости:\n",
        "\n",
        "$$ x_2 =  x - \\alpha \\frac{w^{\\top}x + b}{w^{\\top}w}w \\enspace, $$ \n",
        "где $\\alpha > 1$:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2PpkdfZRwfrY"
      },
      "outputs": [],
      "source": [
        "perturbation = 1.3 * (np.dot(w, x) + b) / np.dot(w, w) * w\n",
        "x2 = x - perturbation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2qJR6LxNwfre"
      },
      "outputs": [],
      "source": [
        "logreg.predict_proba([x2])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D3nm731Ywfrj"
      },
      "source": [
        "Теперь алгоритм уверен, что это 3!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "odpfFsA1wfrl"
      },
      "outputs": [],
      "source": [
        "show(x2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_R_6G7F_wfrp"
      },
      "source": [
        "Для человека она по-прежнему выглядит как 7. Это то, что называется атаки на классификатор: небольшое возмущение x полностью сбивает алгоритм классификации с толку."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eENOcxO-wfrq"
      },
      "outputs": [],
      "source": [
        "np.linalg.norm(perturbation) / np.linalg.norm(x)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3eA89lOzpmf"
      },
      "source": [
        "<img src=\"\n",
        "https://pierreablingithub.files.wordpress.com/2019/04/fig2.png\" align=\"center\" hspace=\"10px\" vspace=\"0px\">"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PdpDmbH2x4wT"
      },
      "source": [
        "Суть состязательной атаки заключается в том, что даже если $x_2$ принадлежит \"другой стороне\" гиперплоскости, он все равно является \"7\" согласно нашему собственному человеческому классификатору."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zpZZxHS3x4wT"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}